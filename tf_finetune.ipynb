{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honoreade/DeepLearning/blob/main/tf_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUKNCj9E_Afp"
      },
      "source": [
        "# **Computing Transfer leaning**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqr39U_sAL7d",
        "outputId": "c6e0d7db-0afd-4bed-ef25-59ee05324e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFV6Bsia-paU"
      },
      "outputs": [],
      "source": [
        "# Dependency libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image size and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create ImageDataGenerator instances for training, validation, and test sets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    channel_shift_range=30.0,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)  # Only rescale for validation and test\n",
        "\n",
        "# Define paths\n",
        "train_data_path = \"/content/drive/MyDrive/Colab Notebooks/FruitClassifier/FruitClassifier/train\"\n",
        "val_data_path = \"/content/drive/MyDrive/Colab Notebooks/FruitClassifier/FruitClassifier/val\"\n",
        "test_data_path = \"/content/drive/MyDrive/Colab Notebooks/FruitClassifier/FruitClassifier/test\"\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"  # For multi-class classification\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False  # No need to shuffle test data\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kT26O1F1eCf",
        "outputId": "09f35b25-1a59-408f-fe38-a27cf1efb937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2489 images belonging to 7 classes.\n",
            "Found 720 images belonging to 7 classes.\n",
            "Found 1400 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNc1pt2W_a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0611962-87e6-469f-e08d-49300aa2fbb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load pre-trained ResNet50 with a defined input shape\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all convolutional base layers initially\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new fully connected layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(train_generator.num_classes, activation=\"softmax\")(x)  # Dynamically set class count\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o28n7GXC_cP4",
        "outputId": "8269ed3e-5b88-4e03-eff1-b05e0b13665b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.2854 - loss: 2.6532 - val_accuracy: 0.2347 - val_loss: 2.4729 - learning_rate: 3.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 710ms/step - accuracy: 0.3083 - loss: 2.2607 - val_accuracy: 0.2667 - val_loss: 2.2845 - learning_rate: 3.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 712ms/step - accuracy: 0.3729 - loss: 2.0801 - val_accuracy: 0.1458 - val_loss: 2.6671 - learning_rate: 3.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 707ms/step - accuracy: 0.3603 - loss: 2.0450 - val_accuracy: 0.1833 - val_loss: 2.4038 - learning_rate: 3.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.3764 - loss: 1.9849 - val_accuracy: 0.2194 - val_loss: 2.6553 - learning_rate: 3.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 721ms/step - accuracy: 0.3718 - loss: 1.9370 - val_accuracy: 0.3139 - val_loss: 2.0304 - learning_rate: 6.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 718ms/step - accuracy: 0.3925 - loss: 1.8707 - val_accuracy: 0.3194 - val_loss: 2.0213 - learning_rate: 6.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 715ms/step - accuracy: 0.4126 - loss: 1.8473 - val_accuracy: 0.3500 - val_loss: 2.0053 - learning_rate: 6.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 713ms/step - accuracy: 0.3963 - loss: 1.8634 - val_accuracy: 0.3583 - val_loss: 1.9104 - learning_rate: 6.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 714ms/step - accuracy: 0.3984 - loss: 1.8585 - val_accuracy: 0.3333 - val_loss: 2.1428 - learning_rate: 6.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a53a01cae90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping\n",
        "\n",
        "# Define Callbacks\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train only the new fully connected layers first\n",
        "model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tune with the 40% of pretrained layers"
      ],
      "metadata": {
        "id": "MeHjKeRcc554"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some deeper layers for fine-tuning\n",
        "for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "MZ2YqEzl6w7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda2c0c5-35ff-4d9a-9aa1-3711ba796112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 935ms/step - accuracy: 0.2739 - loss: 2.2919 - val_accuracy: 0.1431 - val_loss: 7.8872\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 746ms/step - accuracy: 0.3527 - loss: 2.0136 - val_accuracy: 0.2250 - val_loss: 4.9294\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 725ms/step - accuracy: 0.3640 - loss: 1.9111 - val_accuracy: 0.1819 - val_loss: 4.3367\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 727ms/step - accuracy: 0.3893 - loss: 1.8730 - val_accuracy: 0.2931 - val_loss: 2.7461\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 717ms/step - accuracy: 0.4098 - loss: 1.8468 - val_accuracy: 0.3542 - val_loss: 2.0872\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 712ms/step - accuracy: 0.4252 - loss: 1.7858 - val_accuracy: 0.4222 - val_loss: 1.8026\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.4393 - loss: 1.7826 - val_accuracy: 0.4556 - val_loss: 1.7096\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 700ms/step - accuracy: 0.4509 - loss: 1.7401 - val_accuracy: 0.4583 - val_loss: 1.6977\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.4378 - loss: 1.7199 - val_accuracy: 0.4222 - val_loss: 1.7683\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 732ms/step - accuracy: 0.4638 - loss: 1.7263 - val_accuracy: 0.4639 - val_loss: 1.6697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a53ba3ea310>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Try Out Bunch of other Pretained Models**"
      ],
      "metadata": {
        "id": "4eDU6545dG91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0, EfficientNetB1, EfficientNetB6, EfficientNetB7, DenseNet121, DenseNet169, DenseNet201, InceptionV3, ResNet101, ResNet152, VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def train_pretrained_model(model_name, train_generator, validation_generator, epochs=10):\n",
        "    # Dictionary to store model architectures\n",
        "    model_dict = {\n",
        "        \"VGG19\": VGG19,\n",
        "        \"ResNet50\": ResNet50,\n",
        "        \"ResNet101\": ResNet101,\n",
        "        \"ResNet152\": ResNet152,\n",
        "        \"EfficientNetB0\": EfficientNetB0,\n",
        "        \"EfficientNetB1\": EfficientNetB1,\n",
        "        \"EfficientNetB6\": EfficientNetB6,\n",
        "        \"EfficientNetB7\": EfficientNetB7,\n",
        "        \"DenseNet121\": DenseNet121,\n",
        "        \"DenseNet169\": DenseNet169,\n",
        "        \"DenseNet201\": DenseNet201,\n",
        "        \"InceptionV3\": InceptionV3\n",
        "    }\n",
        "\n",
        "    if model_name not in model_dict:\n",
        "        raise ValueError(f\"Invalid model name: {model_name}. Choose from {list(model_dict.keys())}\")\n",
        "\n",
        "    base_model = model_dict[model_name](weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully connected layers with L2 regularization and batch normalization\n",
        "    x = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)  # Dropout to reduce overfitting\n",
        "    output = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "    print(f\"Starting training for {model_name}...\")\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[early_stopping])\n",
        "\n",
        "    print(f\"Training complete for {model_name}. Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "    print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def save_model(model, model_name, save_dir=\"saved_models\"):\n",
        "    \"\"\"Saves the trained model to the specified directory.\"\"\"\n",
        "    import os\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model_path = os.path.join(save_dir, f\"{model_name}.h5\")\n",
        "    model.save(model_path)\n",
        "    print(f\"Model {model_name} saved at {model_path}\")\n",
        "\n",
        "\n",
        "# Example usage (assuming you have train_generator and validation_generator defined):\n",
        "models_to_train = [\n",
        "    \"VGG19\", \"ResNet50\", \"ResNet101\", \"ResNet152\",\n",
        "    \"EfficientNetB0\", \"EfficientNetB1\", \"EfficientNetB6\", \"EfficientNetB7\",\n",
        "    \"DenseNet121\", \"DenseNet169\", \"DenseNet201\", \"InceptionV3\"\n",
        "]\n",
        "\n",
        "for model_name in models_to_train:\n",
        "    trained_model = train_pretrained_model(model_name, train_generator, val_generator)\n",
        "    save_model(trained_model, model_name)\n"
      ],
      "metadata": {
        "id": "CPJFMovH6w0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e469b87-9f4a-4e72-8f7b-096171f829d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Starting training for VGG19...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.3877 - loss: 1.9378 - val_accuracy: 0.3333 - val_loss: 1.6765\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 740ms/step - accuracy: 0.6690 - loss: 1.1422 - val_accuracy: 0.6819 - val_loss: 1.3368\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 733ms/step - accuracy: 0.7081 - loss: 1.0038 - val_accuracy: 0.6875 - val_loss: 1.1173\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 738ms/step - accuracy: 0.7227 - loss: 0.9480 - val_accuracy: 0.7194 - val_loss: 0.9643\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 736ms/step - accuracy: 0.7417 - loss: 0.8860 - val_accuracy: 0.5153 - val_loss: 1.5633\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 810ms/step - accuracy: 0.7459 - loss: 0.8698 - val_accuracy: 0.7764 - val_loss: 0.7980\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 736ms/step - accuracy: 0.7577 - loss: 0.8669 - val_accuracy: 0.7778 - val_loss: 0.8091\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 747ms/step - accuracy: 0.7589 - loss: 0.8144 - val_accuracy: 0.7847 - val_loss: 0.8236\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 755ms/step - accuracy: 0.7765 - loss: 0.7866 - val_accuracy: 0.6542 - val_loss: 1.1604\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 747ms/step - accuracy: 0.7627 - loss: 0.8064 - val_accuracy: 0.8097 - val_loss: 0.7292\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete for VGG19. Final validation accuracy: 0.8097\n",
            "Final validation loss: 0.7292\n",
            "Model VGG19 saved at saved_models/VGG19.h5\n",
            "Starting training for ResNet50...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 843ms/step - accuracy: 0.2061 - loss: 2.1711 - val_accuracy: 0.1472 - val_loss: 2.4162\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 717ms/step - accuracy: 0.3325 - loss: 1.8653 - val_accuracy: 0.1708 - val_loss: 2.3621\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 727ms/step - accuracy: 0.3423 - loss: 1.8260 - val_accuracy: 0.2625 - val_loss: 2.1837\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 716ms/step - accuracy: 0.3542 - loss: 1.7433 - val_accuracy: 0.2722 - val_loss: 2.2982\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 709ms/step - accuracy: 0.3793 - loss: 1.6939 - val_accuracy: 0.2736 - val_loss: 1.9077\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 723ms/step - accuracy: 0.4369 - loss: 1.6199 - val_accuracy: 0.3250 - val_loss: 1.9020\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 779ms/step - accuracy: 0.3893 - loss: 1.6782 - val_accuracy: 0.1472 - val_loss: 4.5726\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 724ms/step - accuracy: 0.4280 - loss: 1.6112 - val_accuracy: 0.2292 - val_loss: 5.2543\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 720ms/step - accuracy: 0.4238 - loss: 1.5949 - val_accuracy: 0.2306 - val_loss: 4.1265\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 716ms/step - accuracy: 0.4111 - loss: 1.6400 - val_accuracy: 0.2069 - val_loss: 3.6620\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete for ResNet50. Final validation accuracy: 0.2069\n",
            "Final validation loss: 3.6620\n",
            "Model ResNet50 saved at saved_models/ResNet50.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171446536/171446536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n",
            "Starting training for ResNet101...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 957ms/step - accuracy: 0.2047 - loss: 2.2035 - val_accuracy: 0.1806 - val_loss: 2.0858\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 732ms/step - accuracy: 0.2751 - loss: 1.9370 - val_accuracy: 0.2278 - val_loss: 1.9238\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 740ms/step - accuracy: 0.3158 - loss: 1.8534 - val_accuracy: 0.1750 - val_loss: 2.0423\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 732ms/step - accuracy: 0.2993 - loss: 1.8402 - val_accuracy: 0.2417 - val_loss: 2.0160\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 733ms/step - accuracy: 0.3334 - loss: 1.8129 - val_accuracy: 0.2181 - val_loss: 2.3525\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 752ms/step - accuracy: 0.3250 - loss: 1.7745 - val_accuracy: 0.3444 - val_loss: 1.8784\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 742ms/step - accuracy: 0.3152 - loss: 1.7694 - val_accuracy: 0.2319 - val_loss: 2.8126\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 736ms/step - accuracy: 0.3765 - loss: 1.7172 - val_accuracy: 0.3083 - val_loss: 2.3615\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 733ms/step - accuracy: 0.3649 - loss: 1.7494 - val_accuracy: 0.3292 - val_loss: 2.1036\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 736ms/step - accuracy: 0.3293 - loss: 1.7768 - val_accuracy: 0.2167 - val_loss: 2.1011\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete for ResNet101. Final validation accuracy: 0.2167\n",
            "Final validation loss: 2.1011\n",
            "Model ResNet101 saved at saved_models/ResNet101.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m234698864/234698864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
            "Starting training for ResNet152...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.1830 - loss: 2.2897 - val_accuracy: 0.1667 - val_loss: 2.1065\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 768ms/step - accuracy: 0.2473 - loss: 1.9919 - val_accuracy: 0.2014 - val_loss: 2.1189\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 775ms/step - accuracy: 0.3247 - loss: 1.8267 - val_accuracy: 0.2097 - val_loss: 1.9682\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 765ms/step - accuracy: 0.2989 - loss: 1.8483 - val_accuracy: 0.2069 - val_loss: 2.2492\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 830ms/step - accuracy: 0.3264 - loss: 1.8203 - val_accuracy: 0.2500 - val_loss: 1.9238\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 760ms/step - accuracy: 0.3322 - loss: 1.8184 - val_accuracy: 0.1694 - val_loss: 2.9435\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 782ms/step - accuracy: 0.3294 - loss: 1.7477 - val_accuracy: 0.1861 - val_loss: 2.6809\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 787ms/step - accuracy: 0.3546 - loss: 1.7264 - val_accuracy: 0.2889 - val_loss: 1.8867\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 758ms/step - accuracy: 0.3422 - loss: 1.7421 - val_accuracy: 0.1903 - val_loss: 2.5994\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 752ms/step - accuracy: 0.3498 - loss: 1.7468 - val_accuracy: 0.2236 - val_loss: 2.5864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete for ResNet152. Final validation accuracy: 0.2236\n",
            "Final validation loss: 2.5864\n",
            "Model ResNet152 saved at saved_models/ResNet152.h5\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Starting training for EfficientNetB0...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 996ms/step - accuracy: 0.1401 - loss: 2.3572 - val_accuracy: 0.1389 - val_loss: 2.1672\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.1396 - loss: 2.2168 - val_accuracy: 0.1667 - val_loss: 2.1480\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 700ms/step - accuracy: 0.1484 - loss: 2.1945 - val_accuracy: 0.1389 - val_loss: 2.1968\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 709ms/step - accuracy: 0.1531 - loss: 2.1701 - val_accuracy: 0.1389 - val_loss: 2.1526\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 713ms/step - accuracy: 0.1640 - loss: 2.1387 - val_accuracy: 0.1389 - val_loss: 2.3715\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 713ms/step - accuracy: 0.1613 - loss: 2.1341 - val_accuracy: 0.1444 - val_loss: 2.5072\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 701ms/step - accuracy: 0.1469 - loss: 2.0976 - val_accuracy: 0.1389 - val_loss: 2.2176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete for EfficientNetB0. Final validation accuracy: 0.1389\n",
            "Final validation loss: 2.2176\n",
            "Model EfficientNetB0 saved at saved_models/EfficientNetB0.h5\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
            "\u001b[1m27018416/27018416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Starting training for EfficientNetB1...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - accuracy: 0.1462 - loss: 2.3819 - val_accuracy: 0.1389 - val_loss: 2.1876\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 701ms/step - accuracy: 0.1578 - loss: 2.2685 - val_accuracy: 0.1389 - val_loss: 2.4584\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 708ms/step - accuracy: 0.1481 - loss: 2.2488 - val_accuracy: 0.1556 - val_loss: 2.0837\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 699ms/step - accuracy: 0.1478 - loss: 2.1838 - val_accuracy: 0.1597 - val_loss: 2.2399\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 694ms/step - accuracy: 0.1552 - loss: 2.1419 - val_accuracy: 0.1681 - val_loss: 2.1835\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 695ms/step - accuracy: 0.1655 - loss: 2.1153 - val_accuracy: 0.1819 - val_loss: 2.0739\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 688ms/step - accuracy: 0.1368 - loss: 2.1272 - val_accuracy: 0.1528 - val_loss: 2.2732\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.1542 - loss: 2.0811 - val_accuracy: 0.1528 - val_loss: 2.0469\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 713ms/step - accuracy: 0.1547 - loss: 2.0812 - val_accuracy: 0.1306 - val_loss: 2.0481\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 719ms/step - accuracy: 0.1605 - loss: 2.0737 - val_accuracy: 0.1847 - val_loss: 1.9883\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for EfficientNetB1. Final validation accuracy: 0.1847\n",
            "Final validation loss: 1.9883\n",
            "Model EfficientNetB1 saved at saved_models/EfficientNetB1.h5\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
            "\u001b[1m165234480/165234480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n",
            "Starting training for EfficientNetB6...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.1537 - loss: 2.3665 - val_accuracy: 0.1417 - val_loss: 2.4559\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 760ms/step - accuracy: 0.1783 - loss: 2.2541 - val_accuracy: 0.1569 - val_loss: 2.1333\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 749ms/step - accuracy: 0.1653 - loss: 2.1722 - val_accuracy: 0.1528 - val_loss: 2.0905\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 744ms/step - accuracy: 0.1743 - loss: 2.1788 - val_accuracy: 0.1389 - val_loss: 2.3864\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 809ms/step - accuracy: 0.1666 - loss: 2.1307 - val_accuracy: 0.1569 - val_loss: 2.1705\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 748ms/step - accuracy: 0.1763 - loss: 2.0996 - val_accuracy: 0.2042 - val_loss: 2.0534\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 751ms/step - accuracy: 0.1831 - loss: 2.0962 - val_accuracy: 0.2083 - val_loss: 2.0135\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 749ms/step - accuracy: 0.1631 - loss: 2.1031 - val_accuracy: 0.1653 - val_loss: 1.9865\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 811ms/step - accuracy: 0.1820 - loss: 2.0440 - val_accuracy: 0.2097 - val_loss: 2.0713\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 747ms/step - accuracy: 0.1880 - loss: 2.0162 - val_accuracy: 0.1528 - val_loss: 2.2048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for EfficientNetB6. Final validation accuracy: 0.1528\n",
            "Final validation loss: 2.2048\n",
            "Model EfficientNetB6 saved at saved_models/EfficientNetB6.h5\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n",
            "Starting training for EfficientNetB7...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step - accuracy: 0.1585 - loss: 2.4047 - val_accuracy: 0.1389 - val_loss: 2.2587\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 829ms/step - accuracy: 0.1659 - loss: 2.2411 - val_accuracy: 0.1389 - val_loss: 2.1706\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 760ms/step - accuracy: 0.1536 - loss: 2.1860 - val_accuracy: 0.1444 - val_loss: 2.1131\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 779ms/step - accuracy: 0.1806 - loss: 2.1389 - val_accuracy: 0.1389 - val_loss: 2.1885\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 766ms/step - accuracy: 0.1444 - loss: 2.1394 - val_accuracy: 0.1736 - val_loss: 2.0259\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 821ms/step - accuracy: 0.1601 - loss: 2.0983 - val_accuracy: 0.1653 - val_loss: 2.0296\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 766ms/step - accuracy: 0.1559 - loss: 2.0801 - val_accuracy: 0.1403 - val_loss: 2.0623\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 775ms/step - accuracy: 0.1367 - loss: 2.0757 - val_accuracy: 0.1639 - val_loss: 2.0332\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 760ms/step - accuracy: 0.1432 - loss: 2.0451 - val_accuracy: 0.1764 - val_loss: 2.0826\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 821ms/step - accuracy: 0.1494 - loss: 2.0311 - val_accuracy: 0.1458 - val_loss: 2.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for EfficientNetB7. Final validation accuracy: 0.1458\n",
            "Final validation loss: 2.0024\n",
            "Model EfficientNetB7 saved at saved_models/EfficientNetB7.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Starting training for DenseNet121...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5645 - loss: 1.5457 - val_accuracy: 0.8625 - val_loss: 0.5312\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 710ms/step - accuracy: 0.8693 - loss: 0.5288 - val_accuracy: 0.9236 - val_loss: 0.3657\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 707ms/step - accuracy: 0.8922 - loss: 0.4593 - val_accuracy: 0.9278 - val_loss: 0.3528\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 708ms/step - accuracy: 0.9199 - loss: 0.3806 - val_accuracy: 0.9389 - val_loss: 0.3229\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 714ms/step - accuracy: 0.8988 - loss: 0.3928 - val_accuracy: 0.9361 - val_loss: 0.3101\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 707ms/step - accuracy: 0.9175 - loss: 0.3529 - val_accuracy: 0.9333 - val_loss: 0.3486\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 715ms/step - accuracy: 0.9226 - loss: 0.3333 - val_accuracy: 0.9125 - val_loss: 0.3984\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 707ms/step - accuracy: 0.9303 - loss: 0.3175 - val_accuracy: 0.9111 - val_loss: 0.3768\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 704ms/step - accuracy: 0.9322 - loss: 0.3126 - val_accuracy: 0.9319 - val_loss: 0.3354\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 708ms/step - accuracy: 0.9400 - loss: 0.3002 - val_accuracy: 0.9111 - val_loss: 0.3870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for DenseNet121. Final validation accuracy: 0.9111\n",
            "Final validation loss: 0.3870\n",
            "Model DenseNet121 saved at saved_models/DenseNet121.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m51877672/51877672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Starting training for DenseNet169...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.6181 - loss: 1.3324 - val_accuracy: 0.8986 - val_loss: 0.4449\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 713ms/step - accuracy: 0.8817 - loss: 0.4506 - val_accuracy: 0.9292 - val_loss: 0.3664\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 730ms/step - accuracy: 0.9092 - loss: 0.3816 - val_accuracy: 0.9208 - val_loss: 0.3636\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 721ms/step - accuracy: 0.9399 - loss: 0.3080 - val_accuracy: 0.9236 - val_loss: 0.3389\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 723ms/step - accuracy: 0.9422 - loss: 0.2987 - val_accuracy: 0.9444 - val_loss: 0.3095\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 729ms/step - accuracy: 0.9394 - loss: 0.3013 - val_accuracy: 0.9431 - val_loss: 0.3093\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 720ms/step - accuracy: 0.9481 - loss: 0.2686 - val_accuracy: 0.8819 - val_loss: 0.5037\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 722ms/step - accuracy: 0.9541 - loss: 0.2487 - val_accuracy: 0.9500 - val_loss: 0.3075\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 720ms/step - accuracy: 0.9556 - loss: 0.2439 - val_accuracy: 0.9306 - val_loss: 0.3457\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 709ms/step - accuracy: 0.9528 - loss: 0.2452 - val_accuracy: 0.9319 - val_loss: 0.3335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for DenseNet169. Final validation accuracy: 0.9319\n",
            "Final validation loss: 0.3335\n",
            "Model DenseNet169 saved at saved_models/DenseNet169.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Starting training for DenseNet201...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.6511 - loss: 1.2658 - val_accuracy: 0.8542 - val_loss: 0.5607\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 739ms/step - accuracy: 0.8829 - loss: 0.4718 - val_accuracy: 0.9042 - val_loss: 0.4143\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 751ms/step - accuracy: 0.9154 - loss: 0.3685 - val_accuracy: 0.9236 - val_loss: 0.3375\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 732ms/step - accuracy: 0.9336 - loss: 0.3057 - val_accuracy: 0.9306 - val_loss: 0.3280\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 730ms/step - accuracy: 0.9376 - loss: 0.2930 - val_accuracy: 0.9403 - val_loss: 0.2873\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 745ms/step - accuracy: 0.9526 - loss: 0.2570 - val_accuracy: 0.9167 - val_loss: 0.3656\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 750ms/step - accuracy: 0.9417 - loss: 0.2597 - val_accuracy: 0.9292 - val_loss: 0.3023\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 736ms/step - accuracy: 0.9572 - loss: 0.2249 - val_accuracy: 0.9333 - val_loss: 0.3120\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 747ms/step - accuracy: 0.9555 - loss: 0.2291 - val_accuracy: 0.9278 - val_loss: 0.3468\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 757ms/step - accuracy: 0.9501 - loss: 0.2447 - val_accuracy: 0.9333 - val_loss: 0.3237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for DenseNet201. Final validation accuracy: 0.9333\n",
            "Final validation loss: 0.3237\n",
            "Model DenseNet201 saved at saved_models/DenseNet201.h5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Starting training for InceptionV3...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.6330 - loss: 1.4055 - val_accuracy: 0.8583 - val_loss: 0.6405\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 758ms/step - accuracy: 0.8285 - loss: 0.7817 - val_accuracy: 0.9042 - val_loss: 0.5004\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 754ms/step - accuracy: 0.8652 - loss: 0.6627 - val_accuracy: 0.9097 - val_loss: 0.4820\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 752ms/step - accuracy: 0.8664 - loss: 0.6339 - val_accuracy: 0.9167 - val_loss: 0.4979\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 764ms/step - accuracy: 0.8814 - loss: 0.5995 - val_accuracy: 0.8889 - val_loss: 0.5538\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 772ms/step - accuracy: 0.8694 - loss: 0.5893 - val_accuracy: 0.9083 - val_loss: 0.4930\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 860ms/step - accuracy: 0.8860 - loss: 0.5706 - val_accuracy: 0.8556 - val_loss: 0.6357\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 808ms/step - accuracy: 0.8749 - loss: 0.5632 - val_accuracy: 0.9097 - val_loss: 0.4674\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 834ms/step - accuracy: 0.8944 - loss: 0.5000 - val_accuracy: 0.8944 - val_loss: 0.4930\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 782ms/step - accuracy: 0.9091 - loss: 0.4936 - val_accuracy: 0.8639 - val_loss: 0.5722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete for InceptionV3. Final validation accuracy: 0.8639\n",
            "Final validation loss: 0.5722\n",
            "Model InceptionV3 saved at saved_models/InceptionV3.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define source and destination folders\n",
        "source_folder = \"/content/saved_models\"\n",
        "destination_folder = \"/content/drive/MyDrive/Colab Notebooks/saved_models\"\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Copy all files from source to destination\n",
        "for file_name in os.listdir(source_folder):\n",
        "    shutil.copy(os.path.join(source_folder, file_name), os.path.join(destination_folder, file_name))\n",
        "\n",
        "print(\"Models copied to Google Drive successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl9nRHwRPR3I",
        "outputId": "7c943ce5-63fe-4489-aa0b-2162df9de69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models copied to Google Drive successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Making inference on top 5 performing Models based on validation Accuracy**"
      ],
      "metadata": {
        "id": "bSLHtQwsU6tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_models(directory, model_names):\n",
        "    \"\"\"Loads only .h5 models from the specified directory that match given model names exactly.\"\"\"\n",
        "    return {\n",
        "        os.path.splitext(f)[0]: tf.keras.models.load_model(os.path.join(directory, f))\n",
        "        for f in os.listdir(directory)\n",
        "        if f.endswith(\".h5\") and os.path.splitext(f)[0] in model_names\n",
        "    }\n",
        "\n",
        "def evaluate_models(models, test_generator):\n",
        "    \"\"\"Evaluates models on the test dataset and returns results.\"\"\"\n",
        "    return {\n",
        "        name: dict(zip([\"Loss\", \"Accuracy\"], model.evaluate(test_generator)))\n",
        "        for name, model in models.items()\n",
        "    }\n",
        "\n",
        "def print_results(results):\n",
        "    \"\"\"Prints the evaluation results.\"\"\"\n",
        "    print(\"\\n=== Test Set Evaluation Results ===\")\n",
        "    for name, metrics in results.items():\n",
        "        print(f\"{name}: Loss = {metrics['Loss']:.4f}, Accuracy = {metrics['Accuracy']:.2%}\")\n",
        "\n",
        "# Define model directory and exact model names to load\n",
        "saved_models_dir = \"/content/drive/MyDrive/Colab Notebooks/saved_models\"\n",
        "target_models = [\"VGG19\", \"DenseNet121\", \"DenseNet169\", \"DenseNet201\", \"InceptionV3\"]\n",
        "\n",
        "# Load, evaluate, and print results for selected models\n",
        "models = load_models(saved_models_dir, target_models)\n",
        "results = evaluate_models(models, test_generator)\n",
        "print_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMlEIAUmc3W4",
        "outputId": "cec1c145-d67f-448a-a2af-105aec13a03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 8s/step - accuracy: 0.9098 - loss: 0.4239\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1072s\u001b[0m 24s/step - accuracy: 0.7978 - loss: 0.7221\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 7s/step - accuracy: 0.9224 - loss: 0.4046\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.8903 - loss: 0.5292\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 9s/step - accuracy: 0.9266 - loss: 0.3358\n",
            "\n",
            "=== Test Set Evaluation Results ===\n",
            "DenseNet121: Loss = 0.3801, Accuracy = 92.21%\n",
            "VGG19: Loss = 0.7600, Accuracy = 79.71%\n",
            "DenseNet169: Loss = 0.3794, Accuracy = 92.64%\n",
            "InceptionV3: Loss = 0.5219, Accuracy = 89.50%\n",
            "DenseNet201: Loss = 0.3234, Accuracy = 93.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **These models seem more promising and if we finetune with half the Pretrained Models unfrozen, that would almost reach to 100%.**"
      ],
      "metadata": {
        "id": "GdKIsjhrWu8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Shout to Regularization Techniques that were applied namely L2 regularization, batch normalization, and Dropout to reduce overfitting!**"
      ],
      "metadata": {
        "id": "hbfa-aCHYPAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **End.**"
      ],
      "metadata": {
        "id": "Z54DbYdCFXSk"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}