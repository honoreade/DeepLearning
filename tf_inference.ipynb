{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honoreade/DeepLearning/blob/main/tf_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_qKwoiTNBq_"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03dEGjgLL8Tv",
        "outputId": "ac10b388-9a0f-4c8d-a340-01f36c759c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytmSLg5ILNKR",
        "outputId": "80955fcc-28f0-435d-cee9-5dd325ea956b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "great_white_shark: 0.9219\n",
            "tiger_shark: 0.0188\n",
            "barracouta: 0.0080\n",
            "sturgeon: 0.0023\n",
            "killer_whale: 0.0020\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the pretrained MobileNetV2 model\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = '/content/drive/MyDrive/Colab Notebooks/images.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# Predict and decode predictions\n",
        "preds = model.predict(img_array)\n",
        "decoded_preds = decode_predictions(preds, top=5)[0]\n",
        "\n",
        "# Print predictions to see if \"banana\" is one of the top predictions\n",
        "for _, class_name, score in decoded_preds:\n",
        "    print(f\"{class_name}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYFHXn67M-wC"
      },
      "source": [
        "#  Making inferences on MobileNetV2, ResNet50, InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5e7N6AILNDr",
        "outputId": "e3989a21-9b1f-48c3-c777-be2a92ed3611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing with MobileNetV2:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "great_white_shark: 0.92\n",
            "tiger_shark: 0.02\n",
            "barracouta: 0.01\n",
            "sturgeon: 0.00\n",
            "killer_whale: 0.00\n",
            "\n",
            "Testing with ResNet50:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "great_white_shark: 0.87\n",
            "tiger_shark: 0.11\n",
            "hammerhead: 0.00\n",
            "killer_whale: 0.00\n",
            "electric_ray: 0.00\n",
            "\n",
            "Testing with InceptionV3:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "great_white_shark: 0.83\n",
            "tiger_shark: 0.13\n",
            "hammerhead: 0.00\n",
            "killer_whale: 0.00\n",
            "electric_ray: 0.00\n"
          ]
        }
      ],
      "source": [
        "# prompt: make the fuction for testing multiple vision pretained model at once\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50, InceptionV3\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobilenet\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def test_multiple_models(image_path):\n",
        "    \"\"\"Tests multiple pretrained vision models on a given image.\n",
        "\n",
        "    Args:\n",
        "        image_path: The path to the image file.\n",
        "    \"\"\"\n",
        "\n",
        "    models = {\n",
        "        \"MobileNetV2\": (MobileNetV2(weights='imagenet'), preprocess_mobilenet, (224, 224)),\n",
        "        \"ResNet50\": (ResNet50(weights='imagenet'), preprocess_resnet, (224, 224)),\n",
        "        \"InceptionV3\": (InceptionV3(weights='imagenet'), preprocess_inception, (299, 299)),\n",
        "    }\n",
        "\n",
        "    for model_name, (model, preprocess_func, target_size) in models.items():\n",
        "      print(f\"\\nTesting with {model_name}:\")\n",
        "      try:\n",
        "        img = image.load_img(image_path, target_size=target_size)\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_func(img_array)\n",
        "\n",
        "        preds = model.predict(img_array)\n",
        "\n",
        "        if model_name == \"MobileNetV2\" or model_name == \"ResNet50\":\n",
        "          decoded_preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=5)[0]\n",
        "        elif model_name == \"InceptionV3\":\n",
        "          decoded_preds = tf.keras.applications.inception_v3.decode_predictions(preds, top=5)[0]\n",
        "\n",
        "        for _, class_name, score in decoded_preds:\n",
        "            print(f\"{class_name}: {score:.2f}\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing {model_name}: {e}\")\n",
        "\n",
        "\n",
        "# Example usage (assuming you have mounted your Google Drive):\n",
        "img_path = '/content/drive/MyDrive/Colab Notebooks/images.jpg'\n",
        "test_multiple_models(img_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkmvzmdoLdGv"
      },
      "source": [
        "# **try RegNet by facebook ai**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsMsa0wOVQgK",
        "outputId": "d16efd20-9855-4472-b6f2-d76ad5897d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RegNet_Y_400MF_Weights.IMAGENET1K_V1`. You can also use `weights=RegNet_Y_400MF_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 2\n"
          ]
        }
      ],
      "source": [
        "# prompt: try RegNet by facebook ai\n",
        "\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load a pre-trained RegNet model\n",
        "model = models.regnet_y_400mf(pretrained=True)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to model's expected input\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load and preprocess an image\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/images.jpg'  # Replace with your image path\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "\n",
        "# Interpret the result\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "predicted_class = torch.argmax(probabilities).item()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Predicted class index: {predicted_class}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbnP2ZWXaP8e",
        "outputId": "ebe3066b-a223-49eb-cacd-2b74c50ead9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: great white shark\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import urllib.request\n",
        "\n",
        "# Download ImageNet class labels\n",
        "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "imagenet_classes = urllib.request.urlopen(url).read().decode(\"utf-8\").split(\"\\n\")\n",
        "\n",
        "# Get the predicted class name\n",
        "predicted_class_name = imagenet_classes[predicted_class]\n",
        "\n",
        "print(f\"Predicted class: {predicted_class_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTE9yAMsLPKg"
      },
      "source": [
        "# **For NASNetLarge Vs NASNetMobile**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oViz_hKeKgmk",
        "outputId": "f22337fb-3eb1-468f-d87f-7ba4efc3e5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
            "NASNetLarge Prediction: [('n01484850', 'great_white_shark', 0.86783826), ('n01491361', 'tiger_shark', 0.035030294), ('n01494475', 'hammerhead', 0.0017078795)]\n",
            "NASNetMobile Prediction: [('n01484850', 'great_white_shark', 0.63411146), ('n01491361', 'tiger_shark', 0.13114019), ('n01494475', 'hammerhead', 0.029718278)]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import NASNetLarge, NASNetMobile\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained models\n",
        "model_large = NASNetLarge(weights=\"imagenet\")\n",
        "model_mobile = NASNetMobile(weights=\"imagenet\")\n",
        "\n",
        "# Function to load and preprocess image with given target size\n",
        "def preprocess_image(image_path, target_size):\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Preprocess for both models\n",
        "img_array_large = preprocess_image(img_path, (331, 331))  # For NASNetLarge\n",
        "img_array_mobile = preprocess_image(img_path, (224, 224)) # For NASNetMobile\n",
        "\n",
        "# Run inference\n",
        "preds_large = model_large.predict(img_array_large)\n",
        "preds_mobile = model_mobile.predict(img_array_mobile)\n",
        "\n",
        "# Decode results\n",
        "print(\"NASNetLarge Prediction:\", decode_predictions(preds_large, top=3)[0])\n",
        "print(\"NASNetMobile Prediction:\", decode_predictions(preds_mobile, top=3)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ABST0hJ-xPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPLtLZujpL5wk7CsYDcZWqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}